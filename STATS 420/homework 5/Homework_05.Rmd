---
output:
  pdf_document: default
  html_document: default
---
### Name - vvgupta2

# Homework 5

## Homework Instructions

For questions that require code, please create a code chunk directly below the question and type your code there. Your knitted pdf will show both your code and your output. You are encouraged to knit your file as you work to check that your coding and formatting is done so appropriately.

For written responses or multiple choice questions, please bold your (selected) answer. 

## Grading Details

All questions will be graded full credit (1 point), half credit (0.5 point) or no credit (0 points). 

Full credit responses should have the correct response and appropriate code (if applicable). Half credit responses will have a reasonable attempt (typically no more than one small error or oversight), and no credit responses will be either non-attempts or attempts with significant errors.


### Exercise 1

Consider testing for significance of regression in a multiple linear regression model with 9 predictors (and an intercept) and 30 observations. If the value of the $F$ test statistic is 2.4, what is the p-value of this test?

```{r}
#solution
n = 30
p = 10
fst = 2.4
pf(2.4, 9, 20, lower.tail = FALSE)
```

### Exercise 2

For the next several exercises, use the `swiss` dataset, which is built into `R`. You should use `?swiss` to learn about the background of this dataset.

Fit a multiple linear regression model with `Fertility` as the response and the remaining variables as predictors.

Use your fitted model to make a prediction for the fertility rate of a Swiss province in 1888 with:

- 54% of males involved in agriculture as occupation 
- 23% of draftees receiving highest mark on army examination
- 13% of draftees obtaining education beyond primary school
- 60% of the population identifying as Catholic
- 24% of live births that live less than a year

```{r}
#solution
?swiss
head(swiss)
names(swiss)
swiss_model = lm (Fertility ~ Agriculture + Examination + Education + Catholic + Infant.Mortality, data = swiss)
summary(swiss_model)
```
```{r}
predict_fert = predict(swiss_model, data.frame(Agriculture = 54, Examination = 23, Education = 13, Catholic = 60, Infant.Mortality = 24), interval = "prediction" )
predict_fert[1]
```


### Exercise 3

Create a 99% confidence interval for the coefficient for `Catholic`. Report both the lower and upper bound.

```{r}
#solution
con_int = confint(swiss_model, level=0.99)
catholic = c(con_int[5], con_int[11])
catholic
```

### Exercise 4

Using the summary output, extract the p-value of the test $H_0: \beta_{\text{Examination}} = 0 \ \text{vs} \ H_1: \beta_{\text{Examination}} \neq 0$

```{r}
#solution
summary(swiss_model)
summary(swiss_model)$coefficients[,4] 
summary(swiss_model)$coefficients[3,4] 
```

### Exercise 5

Interpret the p-value reported in the previous exercise. Which is the most appropriate interpretation?

- If Examination *has no* linear relationship with Fertility, we would expect to see at least this much correlation 31.5% of the time.
- **If Examination *has no* linear relationship with Fertility after controlling for these other 4 predictors, we would expect to see at least this much correlation 31.5% of the time.**

- If Examination *does have* a linear relationship with Fertility, we would expect to see at least this much correlation 31.5% of the time.
- If Examination *does have* a linear relationship with Fertility after controlling for these other 4 predictors, we would expect to see at least this much correlation 31.5% of the time.


### Exercise 6

Create a 95% confidence interval for the average `Fertility` for a Swiss province in 1888 with:

- 40% of males involved in agriculture as occupation 
- 28% of draftees receiving highest mark on army examination
- 10% of draftees obtaining education beyond primary school
- 42% of the population identifying as Catholic
- 27% of live births that live less than a year

Report the **lower** bound of this interval only.

```{r}
#solution
pred_fer_1 = predict(swiss_model, 
        newdata = data.frame(Agriculture = 40, Examination = 28, Education = 10, Catholic = 42, Infant.Mortality = 27), 
        interval = "confidence", 
        level = 0.95)
pred_fer_1
pred_fer_1[2]
```

### Exercise 7

Create a 95% prediction interval for the `Fertility` of a Swiss province in 1888 with:

- 40% of males involved in agriculture as occupation 
- 28% of draftees receiving highest mark on army examination
- 10% of draftees obtaining education beyond primary school
- 42% of the population identifying as Catholic
- 27% of live births that live less than a year

_Yes, these are the same values as for the previous exercise._

Report the **upper** bound of this interval only.

```{r}
#solution
pred_fer_2 = predict(swiss_model, 
        newdata = data.frame(Agriculture = 40, Examination = 28, Education = 10, Catholic = 42, Infant.Mortality = 27), 
        interval = "prediction", 
        level = 0.95)
pred_fer_2[3]
```

### Exercise 8

Run a model summary and observe the F-test result from this model. Determine if this model is explaining a "statistically significant" amount of variance in comparison to the null model. Use $\alpha = 0.01$. What decision do you make?

```{r}
#solution
summary(swiss_model)
```

- Fail to reject $H_0$
- **Reject $H_0$**

- Reject $H_1$
- Not enough information


### Exercise 9

Consider a model that only uses the predictors `Education`, `Catholic`, and `Infant.Mortality`. Use an $F$ test to compare this with the model that uses all predictors. Run an anova to compare these models and extract the p-value of the resulting F-test.

```{r}
#solution
swiss_model_lim = lm (Fertility ~ Education + Catholic + Infant.Mortality, data = swiss)
summary(swiss_model_lim)
table = anova(swiss_model_lim, swiss_model)
table$`Pr(>F)`
```

### Exercise 10

Consider two nested multiple linear regression models fit to the same data (not necessarily the `swiss` data--in general for any data! One has an $R^2$ of 0.9 while the other has an $R^2$ of 0.8. Which model is using fewer predictors?

- **The model with an $R^2$ of 0.9**

- The model with an $R^2$ of 0.8
- Not enough information

### Exercise 11

The following multiple linear regression is fit to data

$$
Y = \beta_0 + \beta_1 x_1  + \beta_2 x_2 + \epsilon
$$

If $\hat{\beta}_1 = 5$ and $\hat{\beta}_2 = 0.25$ then:

- The p-value for testing $H_0: \beta_1 = 0 \ \text{vs} \ H_1: \beta_1 \neq 0$ will be *larger than* the p-value for testing $H_0: \beta_2 = 0 \ \text{vs} \ H_1: \beta_2 \neq 0$.
**- The p-value for testing $H_0: \beta_1 = 0 \ \text{vs} \ H_1: \beta_1 \neq 0$ will be *smaller than* the p-value for testing $H_0: \beta_2 = 0 \ \text{vs} \ H_1: \beta_2 \neq 0$.**

- Not enough information

### Exercise 12

Suppose you have a SLR model for predicting IQ from height. The estimated coefficient for height is positive. Now, we add a predictor for age to create a MLR model. After fitting this new model, which result **could** happen to the estimated coefficient?

- Remain exactly the same as the SLR model.
- Be different, but will still positive.
- Become Zero.
- Become Negative.
- **Any of the above.**



